{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35136b44",
   "metadata": {},
   "source": [
    "# Converting HDF5 to CSV\n",
    "\n",
    "While HDF5 is a format used for storing data values, CSV files are very easy to read and understand. Further, you can directly import them in `pandas` and use them as needed.\n",
    "\n",
    "In this notebook, we'll explore the **2017.h5** from the ERA5 test dataset, identify the values we want to record and create a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3510bdf2",
   "metadata": {},
   "source": [
    "## Load libraries\n",
    "\n",
    "We need the `h5py` package to read the HDF5 file. Further, we'll use `numpy` to work with arrays and `pandas` package to create a final dataset and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11a6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316fdb16",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "We have one data file inside **/data** directory. I'll read the same using the `h5py` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e8b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = h5py.File('../data/globus/ERA5_test/2017.h5', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9e294",
   "metadata": {},
   "source": [
    "## Explore dataset\n",
    "\n",
    "Once the dataset is loaded in, it acts like a Python dictionary. So, we'll start by looking at the various key value pairs and based on them, identify all the values we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444003f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['fields']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532efcec",
   "metadata": {},
   "source": [
    "It appears the HDF5 file has a **fields** inside it. So, let's see the key value pairs inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3fc786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"fields\": shape (1460, 21, 721, 1440), type \"<f4\">"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = dataset['fields']\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd080b0",
   "metadata": {},
   "source": [
    "### fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0eefcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fields data: <HDF5 dataset \"fields\": shape (1460, 21, 721, 1440), type \"<f4\">\n",
      "fields data attributes: []\n"
     ]
    }
   ],
   "source": [
    "print(\"fields data: {}\".format(fields))\n",
    "print(\"fields data attributes: {}\".format(list(fields.attrs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d6e15",
   "metadata": {},
   "source": [
    "21 layers of data temperature etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b615fa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "365*24/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35cecac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 1440)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields[0,0].shape # first day first feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee7a1405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6474845, -0.6474845, -0.6474845, ..., -0.6474845, -0.6474845,\n",
       "       -0.6474845], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a312503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6474845"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925f0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
